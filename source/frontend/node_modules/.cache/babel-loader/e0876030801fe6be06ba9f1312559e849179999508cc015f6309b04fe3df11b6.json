{"ast":null,"code":"import { __assign, __awaiter, __extends, __generator } from \"tslib\";\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport { Category, Credentials, PredictionsAction, getAmplifyUserAgentObject } from '@aws-amplify/core';\nimport { Storage } from '@aws-amplify/storage';\nimport { AbstractIdentifyPredictionsProvider } from '../types/Providers';\nimport { RekognitionClient, SearchFacesByImageCommand, DetectTextCommand, DetectLabelsCommand, DetectFacesCommand, DetectModerationLabelsCommand, RecognizeCelebritiesCommand } from '@aws-sdk/client-rekognition';\nimport { isStorageSource, isFileSource, isBytesSource, isIdentifyCelebrities, isIdentifyFromCollection } from '../types';\nimport { TextractClient, DetectDocumentTextCommand, AnalyzeDocumentCommand } from '@aws-sdk/client-textract';\nimport { makeCamelCase, makeCamelCaseArray, blobToArrayBuffer } from './Utils';\nimport { categorizeRekognitionBlocks, categorizeTextractBlocks } from './IdentifyTextUtils';\nvar AmazonAIIdentifyPredictionsProvider = /** @class */function (_super) {\n  __extends(AmazonAIIdentifyPredictionsProvider, _super);\n  function AmazonAIIdentifyPredictionsProvider() {\n    return _super.call(this) || this;\n  }\n  AmazonAIIdentifyPredictionsProvider.prototype.getProviderName = function () {\n    return 'AmazonAIIdentifyPredictionsProvider';\n  };\n  /**\n   * Verify user input source and converts it into source object readable by Rekognition and Textract.\n   * Note that Rekognition and Textract use the same source interface, so we need not worry about types.\n   * @param {IdentifySource} source - User input source that directs to the object user wants\n   * to identify (storage, file, or bytes).\n   * @return {Promise<Image>} - Promise resolving to the converted source object.\n   */\n  AmazonAIIdentifyPredictionsProvider.prototype.configureSource = function (source) {\n    return new Promise(function (res, rej) {\n      if (isStorageSource(source)) {\n        var storageConfig = {\n          level: source.level,\n          identityId: source.identityId\n        };\n        Storage.get(source.key, storageConfig).then(function (url) {\n          var parser = /https:\\/\\/([a-zA-Z0-9%\\-_.]+)\\.s3\\.[A-Za-z0-9%\\-._~]+\\/([a-zA-Z0-9%\\-._~/]+)\\?/;\n          var parsedURL = url.match(parser);\n          if (parsedURL.length < 3) rej('Invalid S3 key was given.');\n          res({\n            S3Object: {\n              Bucket: parsedURL[1],\n              Name: decodeURIComponent(parsedURL[2])\n            }\n          });\n        }).catch(function (err) {\n          return rej(err);\n        });\n      } else if (isFileSource(source)) {\n        blobToArrayBuffer(source.file).then(function (buffer) {\n          res({\n            Bytes: new Uint8Array(buffer)\n          });\n        }).catch(function (err) {\n          return rej(err);\n        });\n      } else if (isBytesSource(source)) {\n        var bytes = source.bytes;\n        if (bytes instanceof Blob) {\n          blobToArrayBuffer(bytes).then(function (buffer) {\n            res({\n              Bytes: new Uint8Array(buffer)\n            });\n          }).catch(function (err) {\n            return rej(err);\n          });\n        }\n        if (bytes instanceof ArrayBuffer || bytes instanceof Buffer) {\n          res({\n            Bytes: new Uint8Array(bytes)\n          });\n        }\n        // everything else can be directly passed to Rekognition / Textract.\n        res({\n          Bytes: bytes\n        });\n      } else {\n        rej('Input source is not configured correctly.');\n      }\n    });\n  };\n  /**\n   * Recognize text from real-world images and documents (plain text, forms and tables). Detects text in the input\n   * image and converts it into machine-readable text.\n   * @param {IdentifySource} source - Object containing the source image and feature types to analyze.\n   * @return {Promise<IdentifyTextOutput>} - Promise resolving to object containing identified texts.\n   */\n  AmazonAIIdentifyPredictionsProvider.prototype.identifyText = function (input) {\n    return __awaiter(this, void 0, void 0, function () {\n      var credentials, _a, _b, _c, region, _d, _e, configFormat, inputDocument, err_1, format, featureTypes, textractParam, rekognitionParam, detectTextCommand, rekognitionData, rekognitionResponse, detectDocumentTextCommand, Blocks, err_2, param, analyzeDocumentCommand, Blocks, err_3;\n      return __generator(this, function (_f) {\n        switch (_f.label) {\n          case 0:\n            return [4 /*yield*/, Credentials.get()];\n          case 1:\n            credentials = _f.sent();\n            if (!credentials) return [2 /*return*/, Promise.reject('No credentials')];\n            _a = this._config.identifyText, _b = _a === void 0 ? {} : _a, _c = _b.region, region = _c === void 0 ? '' : _c, _d = _b.defaults, _e = (_d === void 0 ? {} : _d).format, configFormat = _e === void 0 ? 'PLAIN' : _e;\n            this.rekognitionClient = new RekognitionClient({\n              region: region,\n              credentials: credentials,\n              customUserAgent: _getPredictionsIdentifyAmplifyUserAgent()\n            });\n            this.textractClient = new TextractClient({\n              region: region,\n              credentials: credentials,\n              customUserAgent: _getPredictionsIdentifyAmplifyUserAgent()\n            });\n            _f.label = 2;\n          case 2:\n            _f.trys.push([2, 4,, 5]);\n            return [4 /*yield*/, this.configureSource(input.text.source)];\n          case 3:\n            inputDocument = _f.sent();\n            return [3 /*break*/, 5];\n          case 4:\n            err_1 = _f.sent();\n            return [2 /*return*/, Promise.reject(err_1)];\n          case 5:\n            format = input.text.format || configFormat;\n            featureTypes = [];\n            if (format === 'FORM' || format === 'ALL') featureTypes.push('FORMS');\n            if (format === 'TABLE' || format === 'ALL') featureTypes.push('TABLES');\n            if (!(featureTypes.length === 0)) return [3 /*break*/, 11];\n            textractParam = {\n              Document: inputDocument\n            };\n            rekognitionParam = {\n              Image: inputDocument\n            };\n            _f.label = 6;\n          case 6:\n            _f.trys.push([6, 9,, 10]);\n            detectTextCommand = new DetectTextCommand(rekognitionParam);\n            return [4 /*yield*/, this.rekognitionClient.send(detectTextCommand)];\n          case 7:\n            rekognitionData = _f.sent();\n            rekognitionResponse = categorizeRekognitionBlocks(rekognitionData.TextDetections);\n            if (rekognitionResponse.text.words.length < 50) {\n              // did not hit the word limit, return the data\n              return [2 /*return*/, rekognitionResponse];\n            }\n            detectDocumentTextCommand = new DetectDocumentTextCommand(textractParam);\n            return [4 /*yield*/, this.textractClient.send(detectDocumentTextCommand)];\n          case 8:\n            Blocks = _f.sent().Blocks;\n            if (rekognitionData.TextDetections.length > Blocks.length) {\n              return [2 /*return*/, rekognitionResponse];\n            }\n            return [2 /*return*/, categorizeTextractBlocks(Blocks)];\n          case 9:\n            err_2 = _f.sent();\n            Promise.reject(err_2);\n            return [3 /*break*/, 10];\n          case 10:\n            return [3 /*break*/, 15];\n          case 11:\n            param = {\n              Document: inputDocument,\n              FeatureTypes: featureTypes\n            };\n            _f.label = 12;\n          case 12:\n            _f.trys.push([12, 14,, 15]);\n            analyzeDocumentCommand = new AnalyzeDocumentCommand(param);\n            return [4 /*yield*/, this.textractClient.send(analyzeDocumentCommand)];\n          case 13:\n            Blocks = _f.sent().Blocks;\n            return [2 /*return*/, categorizeTextractBlocks(Blocks)];\n          case 14:\n            err_3 = _f.sent();\n            return [2 /*return*/, Promise.reject(err_3)];\n          case 15:\n            return [2 /*return*/];\n        }\n      });\n    });\n  };\n  /**\n   * Identify instances of real world entities from an image and if it contains unsafe content.\n   * @param {IdentifyLabelsInput} input - Object containing the source image and entity type to identify.\n   * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to an array of identified entities.\n   */\n  AmazonAIIdentifyPredictionsProvider.prototype.identifyLabels = function (input) {\n    return __awaiter(this, void 0, void 0, function () {\n      var credentials, _a, _b, _c, region, _d, _e, type, inputImage_1, param, servicePromises, entityType, err_4;\n      return __generator(this, function (_f) {\n        switch (_f.label) {\n          case 0:\n            _f.trys.push([0, 3,, 4]);\n            return [4 /*yield*/, Credentials.get()];\n          case 1:\n            credentials = _f.sent();\n            if (!credentials) return [2 /*return*/, Promise.reject('No credentials')];\n            _a = this._config.identifyLabels, _b = _a === void 0 ? {} : _a, _c = _b.region, region = _c === void 0 ? '' : _c, _d = _b.defaults, _e = (_d === void 0 ? {} : _d).type, type = _e === void 0 ? 'LABELS' : _e;\n            this.rekognitionClient = new RekognitionClient({\n              region: region,\n              credentials: credentials,\n              customUserAgent: _getPredictionsIdentifyAmplifyUserAgent()\n            });\n            return [4 /*yield*/, this.configureSource(input.labels.source).then(function (data) {\n              inputImage_1 = data;\n            }).catch(function (err) {\n              return Promise.reject(err);\n            })];\n          case 2:\n            _f.sent();\n            param = {\n              Image: inputImage_1\n            };\n            servicePromises = [];\n            entityType = input.labels.type || type;\n            if (entityType === 'LABELS' || entityType === 'ALL') {\n              servicePromises.push(this.detectLabels(param));\n            }\n            if (entityType === 'UNSAFE' || entityType === 'ALL') {\n              servicePromises.push(this.detectModerationLabels(param));\n            }\n            return [2 /*return*/, Promise.all(servicePromises).then(function (data) {\n              var identifyResult = {};\n              // concatenate resolved promises to a single object\n              data.forEach(function (val) {\n                identifyResult = __assign(__assign({}, identifyResult), val);\n              });\n              return identifyResult;\n            }).catch(function (err) {\n              return Promise.reject(err);\n            })];\n          case 3:\n            err_4 = _f.sent();\n            return [2 /*return*/, Promise.reject(err_4)];\n          case 4:\n            return [2 /*return*/];\n        }\n      });\n    });\n  };\n  /**\n   * Calls Rekognition.detectLabels and organizes the returned data.\n   * @param {DetectLabelsInput} param - parameter to be passed onto Rekognition\n   * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectLabels response.\n   */\n  AmazonAIIdentifyPredictionsProvider.prototype.detectLabels = function (param) {\n    return __awaiter(this, void 0, void 0, function () {\n      var detectLabelsCommand, data, detectLabelData, err_5;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            _a.trys.push([0, 2,, 3]);\n            detectLabelsCommand = new DetectLabelsCommand(param);\n            return [4 /*yield*/, this.rekognitionClient.send(detectLabelsCommand)];\n          case 1:\n            data = _a.sent();\n            if (!data.Labels) return [2 /*return*/, {\n              labels: null\n            }]; // no image was detected\n            detectLabelData = data.Labels.map(function (val) {\n              var boxes = val.Instances ? val.Instances.map(function (val) {\n                return makeCamelCase(val.BoundingBox);\n              }) : undefined;\n              return {\n                name: val.Name,\n                boundingBoxes: boxes,\n                metadata: {\n                  confidence: val.Confidence,\n                  parents: makeCamelCaseArray(val.Parents)\n                }\n              };\n            });\n            return [2 /*return*/, {\n              labels: detectLabelData\n            }];\n          case 2:\n            err_5 = _a.sent();\n            return [2 /*return*/, Promise.reject(err_5)];\n          case 3:\n            return [2 /*return*/];\n        }\n      });\n    });\n  };\n  /**\n   * Calls Rekognition.detectModerationLabels and organizes the returned data.\n   * @param {Rekognition.DetectLabelsRequest} param - Parameter to be passed onto Rekognition\n   * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectModerationLabels response.\n   */\n  AmazonAIIdentifyPredictionsProvider.prototype.detectModerationLabels = function (param) {\n    return __awaiter(this, void 0, void 0, function () {\n      var detectModerationLabelsCommand, data, err_6;\n      return __generator(this, function (_a) {\n        switch (_a.label) {\n          case 0:\n            _a.trys.push([0, 2,, 3]);\n            detectModerationLabelsCommand = new DetectModerationLabelsCommand(param);\n            return [4 /*yield*/, this.rekognitionClient.send(detectModerationLabelsCommand)];\n          case 1:\n            data = _a.sent();\n            if (data.ModerationLabels.length !== 0) {\n              return [2 /*return*/, {\n                unsafe: 'YES'\n              }];\n            } else {\n              return [2 /*return*/, {\n                unsafe: 'NO'\n              }];\n            }\n            return [3 /*break*/, 3];\n          case 2:\n            err_6 = _a.sent();\n            return [2 /*return*/, Promise.reject(err_6)];\n          case 3:\n            return [2 /*return*/];\n        }\n      });\n    });\n  };\n  /**\n   * Identify faces within an image that is provided as input, and match faces from a collection\n   * or identify celebrities.\n   * @param {IdentifyEntityInput} input - object containing the source image and face match options.\n   * @return {Promise<IdentifyEntityOutput>} Promise resolving to identify results.\n   */\n  AmazonAIIdentifyPredictionsProvider.prototype.identifyEntities = function (input) {\n    return __awaiter(this, void 0, void 0, function () {\n      var credentials, _a, _b, _c, region, _d, celebrityDetectionEnabled, _e, _f, _g, collectionIdConfig, _h, maxFacesConfig, inputImage, param, recognizeCelebritiesCommand, data, faces, err_7, _j, _k, collectionId, _l, maxFaces, updatedParam, searchFacesByImageCommand, data, faces, err_8, detectFacesCommand, data, faces, err_9;\n      var _this = this;\n      return __generator(this, function (_m) {\n        switch (_m.label) {\n          case 0:\n            return [4 /*yield*/, Credentials.get()];\n          case 1:\n            credentials = _m.sent();\n            if (!credentials) return [2 /*return*/, Promise.reject('No credentials')];\n            _a = this._config.identifyEntities, _b = _a === void 0 ? {} : _a, _c = _b.region, region = _c === void 0 ? '' : _c, _d = _b.celebrityDetectionEnabled, celebrityDetectionEnabled = _d === void 0 ? false : _d, _e = _b.defaults, _f = _e === void 0 ? {} : _e, _g = _f.collectionId, collectionIdConfig = _g === void 0 ? '' : _g, _h = _f.maxEntities, maxFacesConfig = _h === void 0 ? 50 : _h;\n            // default arguments\n            this.rekognitionClient = new RekognitionClient({\n              region: region,\n              credentials: credentials,\n              customUserAgent: _getPredictionsIdentifyAmplifyUserAgent()\n            });\n            return [4 /*yield*/, this.configureSource(input.entities.source).then(function (data) {\n              return inputImage = data;\n            }).catch(function (err) {\n              return Promise.reject(err);\n            })];\n          case 2:\n            _m.sent();\n            param = {\n              Attributes: ['ALL'],\n              Image: inputImage\n            };\n            if (!(isIdentifyCelebrities(input.entities) && input.entities.celebrityDetection)) return [3 /*break*/, 7];\n            if (!celebrityDetectionEnabled) {\n              return [2 /*return*/, Promise.reject('Error: You have to enable celebrity detection first')];\n            }\n            _m.label = 3;\n          case 3:\n            _m.trys.push([3, 5,, 6]);\n            recognizeCelebritiesCommand = new RecognizeCelebritiesCommand(param);\n            return [4 /*yield*/, this.rekognitionClient.send(recognizeCelebritiesCommand)];\n          case 4:\n            data = _m.sent();\n            faces = data.CelebrityFaces.map(function (celebrity) {\n              return {\n                boundingBox: makeCamelCase(celebrity.Face.BoundingBox),\n                landmarks: makeCamelCaseArray(celebrity.Face.Landmarks),\n                metadata: __assign(__assign({}, makeCamelCase(celebrity, ['Id', 'Name', 'Urls'])), {\n                  pose: makeCamelCase(celebrity.Face.Pose)\n                })\n              };\n            });\n            return [2 /*return*/, {\n              entities: faces\n            }];\n          case 5:\n            err_7 = _m.sent();\n            return [2 /*return*/, Promise.reject(err_7)];\n          case 6:\n            return [3 /*break*/, 15];\n          case 7:\n            if (!(isIdentifyFromCollection(input.entities) && input.entities.collection)) return [3 /*break*/, 12];\n            _j = input.entities, _k = _j.collectionId, collectionId = _k === void 0 ? collectionIdConfig : _k, _l = _j.maxEntities, maxFaces = _l === void 0 ? maxFacesConfig : _l;\n            updatedParam = __assign(__assign({}, param), {\n              CollectionId: collectionId,\n              MaxFaces: maxFaces\n            });\n            _m.label = 8;\n          case 8:\n            _m.trys.push([8, 10,, 11]);\n            searchFacesByImageCommand = new SearchFacesByImageCommand(updatedParam);\n            return [4 /*yield*/, this.rekognitionClient.send(searchFacesByImageCommand)];\n          case 9:\n            data = _m.sent();\n            faces = data.FaceMatches.map(function (val) {\n              return {\n                boundingBox: makeCamelCase(val.Face.BoundingBox),\n                metadata: {\n                  externalImageId: _this.decodeExternalImageId(val.Face.ExternalImageId),\n                  similarity: val.Similarity\n                }\n              };\n            });\n            return [2 /*return*/, {\n              entities: faces\n            }];\n          case 10:\n            err_8 = _m.sent();\n            return [2 /*return*/, Promise.reject(err_8)];\n          case 11:\n            return [3 /*break*/, 15];\n          case 12:\n            _m.trys.push([12, 14,, 15]);\n            detectFacesCommand = new DetectFacesCommand(param);\n            return [4 /*yield*/, this.rekognitionClient.send(detectFacesCommand)];\n          case 13:\n            data = _m.sent();\n            faces = data.FaceDetails.map(function (detail) {\n              // face attributes keys we want to extract from Rekognition's response\n              var attributeKeys = ['Smile', 'Eyeglasses', 'Sunglasses', 'Gender', 'Beard', 'Mustache', 'EyesOpen', 'MouthOpen'];\n              var faceAttributes = makeCamelCase(detail, attributeKeys);\n              if (detail.Emotions) {\n                faceAttributes['emotions'] = detail.Emotions.map(function (emotion) {\n                  return emotion.Type;\n                });\n              }\n              return {\n                boundingBox: makeCamelCase(detail.BoundingBox),\n                landmarks: makeCamelCaseArray(detail.Landmarks),\n                ageRange: makeCamelCase(detail.AgeRange),\n                attributes: faceAttributes,\n                metadata: {\n                  confidence: detail.Confidence,\n                  pose: makeCamelCase(detail.Pose)\n                }\n              };\n            });\n            return [2 /*return*/, {\n              entities: faces\n            }];\n          case 14:\n            err_9 = _m.sent();\n            return [2 /*return*/, Promise.reject(err_9)];\n          case 15:\n            return [2 /*return*/];\n        }\n      });\n    });\n  };\n\n  AmazonAIIdentifyPredictionsProvider.prototype.decodeExternalImageId = function (externalImageId) {\n    return ('' + externalImageId).replace(/::/g, '/');\n  };\n  return AmazonAIIdentifyPredictionsProvider;\n}(AbstractIdentifyPredictionsProvider);\nexport { AmazonAIIdentifyPredictionsProvider };\nfunction _getPredictionsIdentifyAmplifyUserAgent() {\n  return getAmplifyUserAgentObject({\n    category: Category.Predictions,\n    action: PredictionsAction.Identify\n  });\n}","map":{"version":3,"mappings":";AAAA;AACA;AACA,SACCA,QAAQ,EACRC,WAAW,EAEXC,iBAAiB,EACjBC,yBAAyB,QACnB,mBAAmB;AAC1B,SAASC,OAAO,QAAQ,sBAAsB;AAC9C,SAASC,mCAAmC,QAAQ,oBAAoB;AACxE,SACCC,iBAAiB,EACjBC,yBAAyB,EACzBC,iBAAiB,EAEjBC,mBAAmB,EAEnBC,kBAAkB,EAClBC,6BAA6B,EAE7BC,2BAA2B,QACrB,6BAA6B;AACpC,SAMCC,eAAe,EACfC,YAAY,EACZC,aAAa,EAGbC,qBAAqB,EACrBC,wBAAwB,QAGlB,UAAU;AAOjB,SACCC,cAAc,EACdC,yBAAyB,EAEzBC,sBAAsB,QAEhB,0BAA0B;AACjC,SAASC,aAAa,EAAEC,kBAAkB,EAAEC,iBAAiB,QAAQ,SAAS;AAC9E,SACCC,2BAA2B,EAC3BC,wBAAwB,QAClB,qBAAqB;AAE5B;EAAyDC;EAIxD;WACCC,iBAAO;EACR;EAEAC,6DAAe,GAAf;IACC,OAAO,qCAAqC;EAC7C,CAAC;EAED;;;;;;;EAOQA,6DAAe,GAAvB,UAAwBC,MAAsB;IAC7C,OAAO,IAAIC,OAAO,CAAC,UAACC,GAAG,EAAEC,GAAG;MAC3B,IAAInB,eAAe,CAACgB,MAAM,CAAC,EAAE;QAC5B,IAAMI,aAAa,GAAG;UACrBC,KAAK,EAAEL,MAAM,CAACK,KAAK;UACnBC,UAAU,EAAEN,MAAM,CAACM;SACnB;QACD/B,OAAO,CAACgC,GAAG,CAACP,MAAM,CAACQ,GAAG,EAAEJ,aAAa,CAAC,CACpCK,IAAI,CAAC,UAACC,GAAW;UACjB,IAAMC,MAAM,GACX,gFAAgF;UACjF,IAAMC,SAAS,GAAGF,GAAG,CAACG,KAAK,CAACF,MAAM,CAAC;UACnC,IAAIC,SAAS,CAACE,MAAM,GAAG,CAAC,EAAEX,GAAG,CAAC,2BAA2B,CAAC;UAC1DD,GAAG,CAAC;YACHa,QAAQ,EAAE;cACTC,MAAM,EAAEJ,SAAS,CAAC,CAAC,CAAC;cACpBK,IAAI,EAAEC,kBAAkB,CAACN,SAAS,CAAC,CAAC,CAAC;;WAEtC,CAAC;QACH,CAAC,CAAC,CACDO,KAAK,CAAC,aAAG;UAAI,UAAG,CAACC,GAAG,CAAC;QAAR,CAAQ,CAAC;OACxB,MAAM,IAAInC,YAAY,CAACe,MAAM,CAAC,EAAE;QAChCN,iBAAiB,CAACM,MAAM,CAACqB,IAAI,CAAC,CAC5BZ,IAAI,CAAC,gBAAM;UACXP,GAAG,CAAC;YAAEoB,KAAK,EAAE,IAAIC,UAAU,CAACC,MAAM;UAAC,CAAE,CAAC;QACvC,CAAC,CAAC,CACDL,KAAK,CAAC,aAAG;UAAI,UAAG,CAACC,GAAG,CAAC;QAAR,CAAQ,CAAC;OACxB,MAAM,IAAIlC,aAAa,CAACc,MAAM,CAAC,EAAE;QACjC,IAAMyB,KAAK,GAAGzB,MAAM,CAACyB,KAAK;QAC1B,IAAIA,KAAK,YAAYC,IAAI,EAAE;UAC1BhC,iBAAiB,CAAC+B,KAAK,CAAC,CACtBhB,IAAI,CAAC,gBAAM;YACXP,GAAG,CAAC;cAAEoB,KAAK,EAAE,IAAIC,UAAU,CAACC,MAAM;YAAC,CAAE,CAAC;UACvC,CAAC,CAAC,CACDL,KAAK,CAAC,aAAG;YAAI,UAAG,CAACC,GAAG,CAAC;UAAR,CAAQ,CAAC;;QAEzB,IAAIK,KAAK,YAAYE,WAAW,IAAIF,KAAK,YAAYG,MAAM,EAAE;UAC5D1B,GAAG,CAAC;YAAEoB,KAAK,EAAE,IAAIC,UAAU,CAACE,KAAK;UAAC,CAAW,CAAC;;QAE/C;QACAvB,GAAG,CAAC;UAAEoB,KAAK,EAAEG;QAAK,CAAW,CAAC;OAC9B,MAAM;QACNtB,GAAG,CAAC,2CAA2C,CAAC;;IAElD,CAAC,CAAC;EACH,CAAC;EAED;;;;;;EAMgBJ,0DAAY,GAA5B,UACC8B,KAAwB;;;;;;YAEJ,qBAAMzD,WAAW,CAACmC,GAAG,EAAE;;YAArCuB,WAAW,GAAGC,SAAuB;YAC3C,IAAI,CAACD,WAAW,EAAE,sBAAO7B,OAAO,CAAC+B,MAAM,CAAC,gBAAgB,CAAC;YAExDC,KAIG,IAAI,CAACC,OAAO,aADT,EAHNC,qBAGI,EAAE,OAFLC,cAAW,EAAXC,MAAM,mBAAG,EAAE,OACXC,gBAAiD,EAArCC,sBAAmC,EAAE,aAAP,EAAtBC,YAAY,mBAAG,OAAO;YAG5C,IAAI,CAACC,iBAAiB,GAAG,IAAIhE,iBAAiB,CAAC;cAC9C4D,MAAM;cACNP,WAAW;cACXY,eAAe,EAAEC,uCAAuC;aACxD,CAAC;YACF,IAAI,CAACC,cAAc,GAAG,IAAIvD,cAAc,CAAC;cACxCgD,MAAM;cACNP,WAAW;cACXY,eAAe,EAAEC,uCAAuC;aACxD,CAAC;;;;YAIe,qBAAM,IAAI,CAACE,eAAe,CAAChB,KAAK,CAACiB,IAAI,CAAC9C,MAAM,CAAC;;YAA7D+C,aAAa,GAAGhB,SAA6C;;;;YAE7D,sBAAO9B,OAAO,CAAC+B,MAAM,CAACgB,KAAG,CAAC;;YAIrBC,MAAM,GAAGpB,KAAK,CAACiB,IAAI,CAACG,MAAM,IAAIT,YAAY;YAC1CU,YAAY,GAAiB,EAAE;YACrC,IAAID,MAAM,KAAK,MAAM,IAAIA,MAAM,KAAK,KAAK,EAAEC,YAAY,CAACC,IAAI,CAAC,OAAO,CAAC;YACrE,IAAIF,MAAM,KAAK,OAAO,IAAIA,MAAM,KAAK,KAAK,EAAEC,YAAY,CAACC,IAAI,CAAC,QAAQ,CAAC;kBAEnED,YAAY,CAACpC,MAAM,KAAK,CAAC,GAAzB;YAMGsC,aAAa,GAAmC;cACrDC,QAAQ,EAAEN;aACV;YACKO,gBAAgB,GAA2B;cAChDC,KAAK,EAAER;aACP;;;;YAGMS,iBAAiB,GAAG,IAAI7E,iBAAiB,CAAC2E,gBAAgB,CAAC;YACzC,qBAAM,IAAI,CAACb,iBAAiB,CAACgB,IAAI,CACxDD,iBAAiB,CACjB;;YAFKE,eAAe,GAAG3B,SAEvB;YAEK4B,mBAAmB,GAAGhE,2BAA2B,CACtD+D,eAAe,CAACE,cAAmC,CACnD;YACD,IAAID,mBAAmB,CAACb,IAAI,CAACe,KAAK,CAAC/C,MAAM,GAAG,EAAE,EAAE;cAC/C;cACA,sBAAO6C,mBAAmB;;YAGrBG,yBAAyB,GAAG,IAAIxE,yBAAyB,CAC9D8D,aAAa,CACb;YAEkB,qBAAM,IAAI,CAACR,cAAc,CAACa,IAAI,CAChDK,yBAAyB,CACzB;;YAFOC,MAAM,GAAKhC,SAElB,OAFa;YAId,IAAI2B,eAAe,CAACE,cAAc,CAAC9C,MAAM,GAAGiD,MAAM,CAACjD,MAAM,EAAE;cAC1D,sBAAO6C,mBAAmB;;YAG3B,sBAAO/D,wBAAwB,CAACmE,MAAmB,CAAC;;;YAEpD9D,OAAO,CAAC+B,MAAM,CAACgC,KAAG,CAAC;;;;;YAGdC,KAAK,GAAgC;cAC1CZ,QAAQ,EAAEN,aAAa;cACvBmB,YAAY,EAAEhB;aACd;;;;YAGMiB,sBAAsB,GAAG,IAAI5E,sBAAsB,CAAC0E,KAAK,CAAC;YAC7C,qBAAM,IAAI,CAACrB,cAAc,CAACa,IAAI,CAChDU,sBAAsB,CACtB;;YAFOJ,MAAM,GAAKhC,SAElB,OAFa;YAGd,sBAAOnC,wBAAwB,CAACmE,MAAmB,CAAC;;;YAEpD,sBAAO9D,OAAO,CAAC+B,MAAM,CAACoC,KAAG,CAAC;;;;;;GAG5B;EAED;;;;;EAKgBrE,4DAAc,GAA9B,UACC8B,KAA0B;;;;;;;YAGL,qBAAMzD,WAAW,CAACmC,GAAG,EAAE;;YAArCuB,WAAW,GAAGC,SAAuB;YAC3C,IAAI,CAACD,WAAW,EAAE,sBAAO7B,OAAO,CAAC+B,MAAM,CAAC,gBAAgB,CAAC;YAExDC,KAIG,IAAI,CAACC,OAAO,eADT,EAHNC,qBAGI,EAAE,OAFLC,cAAW,EAAXC,MAAM,mBAAG,EAAE,OACXC,gBAAkC,EAAtBC,sBAAoB,EAAE,WAAP,EAAf8B,IAAI,mBAAG,QAAQ;YAG7B,IAAI,CAAC5B,iBAAiB,GAAG,IAAIhE,iBAAiB,CAAC;cAC9C4D,MAAM;cACNP,WAAW;cACXY,eAAe,EAAEC,uCAAuC;aACxD,CAAC;YAEF,qBAAM,IAAI,CAACE,eAAe,CAAChB,KAAK,CAACyC,MAAM,CAACtE,MAAM,CAAC,CAC7CS,IAAI,CAAC,cAAI;cACT8D,YAAU,GAAGC,IAAI;YAClB,CAAC,CAAC,CACDrD,KAAK,CAAC,aAAG;cACT,OAAOlB,OAAO,CAAC+B,MAAM,CAACZ,GAAG,CAAC;YAC3B,CAAC,CAAC;;YANHW,SAMG;YACGkC,KAAK,GAAG;cAAEV,KAAK,EAAEgB;YAAU,CAAE;YAC7BE,eAAe,GAAG,EAAE;YAGpBC,UAAU,GAAG7C,KAAK,CAACyC,MAAM,CAACD,IAAI,IAAIA,IAAI;YAC5C,IAAIK,UAAU,KAAK,QAAQ,IAAIA,UAAU,KAAK,KAAK,EAAE;cACpDD,eAAe,CAACtB,IAAI,CAAC,IAAI,CAACwB,YAAY,CAACV,KAAK,CAAC,CAAC;;YAE/C,IAAIS,UAAU,KAAK,QAAQ,IAAIA,UAAU,KAAK,KAAK,EAAE;cACpDD,eAAe,CAACtB,IAAI,CAAC,IAAI,CAACyB,sBAAsB,CAACX,KAAK,CAAC,CAAC;;YAGzD,sBAAOhE,OAAO,CAAC4E,GAAG,CAACJ,eAAe,CAAC,CACjChE,IAAI,CAAC,cAAI;cACT,IAAIqE,cAAc,GAAyB,EAAE;cAC7C;cACAN,IAAI,CAACO,OAAO,CAAC,aAAG;gBACfD,cAAc,yBAAQA,cAAc,GAAKE,GAAG,CAAE;cAC/C,CAAC,CAAC;cACF,OAAOF,cAAc;YACtB,CAAC,CAAC,CACD3D,KAAK,CAAC,aAAG;cAAI,cAAO,CAACa,MAAM,CAACZ,GAAG,CAAC;YAAnB,CAAmB,CAAC;;;YAEnC,sBAAOnB,OAAO,CAAC+B,MAAM,CAACiD,KAAG,CAAC;;;;;;GAE3B;EAED;;;;;EAKclF,0DAAY,GAA1B,UACCkE,KAA+B;;;;;;;YAGxBiB,mBAAmB,GAAG,IAAItG,mBAAmB,CAACqF,KAAK,CAAC;YAC7C,qBAAM,IAAI,CAACxB,iBAAiB,CAACgB,IAAI,CAACyB,mBAAmB,CAAC;;YAA7DV,IAAI,GAAGvC,SAAsD;YACnE,IAAI,CAACuC,IAAI,CAACW,MAAM,EAAE,sBAAO;cAAEb,MAAM,EAAE;YAAI,CAAE,EAAC,CAAC;YACrCc,eAAe,GAAGZ,IAAI,CAACW,MAAM,CAACE,GAAG,CAAC,aAAG;cAC1C,IAAMC,KAAK,GAAGN,GAAG,CAACO,SAAS,GACxBP,GAAG,CAACO,SAAS,CAACF,GAAG,CAAC,aAAG;gBAAI,oBAAa,CAACL,GAAG,CAACQ,WAAW,CAAC;cAA9B,CAA8B,CAAC,GACxDC,SAAS;cACZ,OAAO;gBACNC,IAAI,EAAEV,GAAG,CAAC/D,IAAI;gBACd0E,aAAa,EAAEL,KAAK;gBACpBM,QAAQ,EAAE;kBACTC,UAAU,EAAEb,GAAG,CAACc,UAAU;kBAC1BC,OAAO,EAAEtG,kBAAkB,CAACuF,GAAG,CAACgB,OAAO;;eAExC;YACF,CAAC,CAAC;YACF,sBAAO;cAAE1B,MAAM,EAAEc;YAAe,CAAE;;;YAElC,sBAAOnF,OAAO,CAAC+B,MAAM,CAACiE,KAAG,CAAC;;;;;;GAE3B;EAED;;;;;EAKclG,oEAAsB,GAApC,UACCkE,KAAyC;;;;;;;YAGlCiC,6BAA6B,GAAG,IAAIpH,6BAA6B,CACtEmF,KAAK,CACL;YACY,qBAAM,IAAI,CAACxB,iBAAiB,CAACgB,IAAI,CAC7CyC,6BAA6B,CAC7B;;YAFK1B,IAAI,GAAGvC,SAEZ;YACD,IAAIuC,IAAI,CAAC2B,gBAAgB,CAACrF,MAAM,KAAK,CAAC,EAAE;cACvC,sBAAO;gBAAEsF,MAAM,EAAE;cAAK,CAAE;aACxB,MAAM;cACN,sBAAO;gBAAEA,MAAM,EAAE;cAAI,CAAE;;;;;YAGxB,sBAAOnG,OAAO,CAAC+B,MAAM,CAACqE,KAAG,CAAC;;;;;;GAE3B;EAED;;;;;;EAMgBtG,8DAAgB,GAAhC,UACC8B,KAA4B;;;;;;;YAER,qBAAMzD,WAAW,CAACmC,GAAG,EAAE;;YAArCuB,WAAW,GAAGwE,SAAuB;YAC3C,IAAI,CAACxE,WAAW,EAAE,sBAAO7B,OAAO,CAAC+B,MAAM,CAAC,gBAAgB,CAAC;YAExDC,KAQG,IAAI,CAACC,OAAO,iBADT,EAPNC,qBAOI,EAAE,OANLC,cAAW,EAAXC,MAAM,mBAAG,EAAE,OACXC,iCAAiC,EAAjCiE,yBAAyB,mBAAG,KAAK,OACjChE,gBAGM,EAHNR,qBAGI,EAAE,OAFLyE,oBAAqC,EAAvBC,kBAAkB,mBAAG,EAAE,OACrCC,mBAAgC,EAAnBC,cAAc,mBAAG,EAAE;YAInC;YAEA,IAAI,CAAClE,iBAAiB,GAAG,IAAIhE,iBAAiB,CAAC;cAC9C4D,MAAM;cACNP,WAAW;cACXY,eAAe,EAAEC,uCAAuC;aACxD,CAAC;YAEF,qBAAM,IAAI,CAACE,eAAe,CAAChB,KAAK,CAAC+E,QAAQ,CAAC5G,MAAM,CAAC,CAC/CS,IAAI,CAAC,cAAI;cAAI,OAACoG,UAAU,GAAGrC,IAAI;YAAlB,CAAmB,CAAC,CACjCrD,KAAK,CAAC,aAAG;cACT,OAAOlB,OAAO,CAAC+B,MAAM,CAACZ,GAAG,CAAC;YAC3B,CAAC,CAAC;;YAJHkF,SAIG;YAEGrC,KAAK,GAAG;cAAE6C,UAAU,EAAE,CAAC,KAAK,CAAC;cAAEvD,KAAK,EAAEsD;YAAU,CAAE;kBAGvD1H,qBAAqB,CAAC0C,KAAK,CAAC+E,QAAQ,CAAC,IACrC/E,KAAK,CAAC+E,QAAQ,CAACG,kBAAkB,GADjC;YAGA,IAAI,CAACR,yBAAyB,EAAE;cAC/B,sBAAOtG,OAAO,CAAC+B,MAAM,CACpB,qDAAqD,CACrD;;;;;YAGKgF,2BAA2B,GAAG,IAAIjI,2BAA2B,CAClEkF,KAAK,CACL;YACY,qBAAM,IAAI,CAACxB,iBAAiB,CAACgB,IAAI,CAC7CuD,2BAA2B,CAC3B;;YAFKxC,IAAI,GAAG8B,SAEZ;YACKW,KAAK,GAAGzC,IAAI,CAAC0C,cAAc,CAAC7B,GAAG,CAAC,mBAAS;cAC9C,OAAO;gBACN8B,WAAW,EAAE3H,aAAa,CAAC4H,SAAS,CAACC,IAAI,CAAC7B,WAAW,CAAC;gBACtD8B,SAAS,EAAE7H,kBAAkB,CAAC2H,SAAS,CAACC,IAAI,CAACE,SAAS,CAAC;gBACvD3B,QAAQ,wBACJpG,aAAa,CAAC4H,SAAS,EAAE,CAAC,IAAI,EAAE,MAAM,EAAE,MAAM,CAAC,CAAC;kBACnDI,IAAI,EAAEhI,aAAa,CAAC4H,SAAS,CAACC,IAAI,CAACI,IAAI;gBAAC;eAEzC;YACF,CAAC,CAAC;YACF,sBAAO;cAAEb,QAAQ,EAAEK;YAAK,CAAE;;;YAE1B,sBAAOhH,OAAO,CAAC+B,MAAM,CAAC0F,KAAG,CAAC;;;;kBAG3BtI,wBAAwB,CAACyC,KAAK,CAAC+E,QAAQ,CAAC,IACxC/E,KAAK,CAAC+E,QAAQ,CAACe,UAAU,GADzB;YAGMC,KAGF/F,KAAK,CAAC+E,QAAkC,EAF3CiB,oBAAiC,EAAjCC,YAAY,mBAAGrB,kBAAkB,OACjCsB,mBAAsC,EAAzBC,QAAQ,mBAAGrB,cAAc;YAGjCsB,YAAY,yBACdhE,KAAK;cACRiE,YAAY,EAAEJ,YAAY;cAC1BK,QAAQ,EAAEH;YAAQ,EAClB;;;;YAEMI,yBAAyB,GAAG,IAAI1J,yBAAyB,CAC9DuJ,YAAY,CACZ;YACY,qBAAM,IAAI,CAACxF,iBAAiB,CAACgB,IAAI,CAC7C2E,yBAAyB,CACzB;;YAFK5D,IAAI,GAAG8B,SAEZ;YACKW,KAAK,GAAGzC,IAAI,CAAC6D,WAAW,CAAChD,GAAG,CAAC,aAAG;cACrC,OAAO;gBACN8B,WAAW,EAAE3H,aAAa,CAACwF,GAAG,CAACqC,IAAI,CAAC7B,WAAW,CAAC;gBAChDI,QAAQ,EAAE;kBACT0C,eAAe,EAAEC,KAAI,CAACC,qBAAqB,CAC1CxD,GAAG,CAACqC,IAAI,CAACoB,eAAe,CACxB;kBACDC,UAAU,EAAE1D,GAAG,CAAC2D;;eAEjB;YACF,CAAC,CAAC;YACF,sBAAO;cAAE/B,QAAQ,EAAEK;YAAK,CAAE;;;YAE1B,sBAAOhH,OAAO,CAAC+B,MAAM,CAAC4G,KAAG,CAAC;;;;;YAIpBC,kBAAkB,GAAG,IAAIhK,kBAAkB,CAACoF,KAAK,CAAC;YAC3C,qBAAM,IAAI,CAACxB,iBAAiB,CAACgB,IAAI,CAACoF,kBAAkB,CAAC;;YAA5DrE,IAAI,GAAG8B,SAAqD;YAC5DW,KAAK,GAAGzC,IAAI,CAACsE,WAAW,CAACzD,GAAG,CAAC,gBAAM;cACxC;cACA,IAAM0D,aAAa,GAAG,CACrB,OAAO,EACP,YAAY,EACZ,YAAY,EACZ,QAAQ,EACR,OAAO,EACP,UAAU,EACV,UAAU,EACV,WAAW,CACX;cACD,IAAMC,cAAc,GAAGxJ,aAAa,CAACyJ,MAAM,EAAEF,aAAa,CAAC;cAC3D,IAAIE,MAAM,CAACC,QAAQ,EAAE;gBACpBF,cAAc,CAAC,UAAU,CAAC,GAAGC,MAAM,CAACC,QAAQ,CAAC7D,GAAG,CAC/C,iBAAO;kBAAI,cAAO,CAAC8D,IAAI;gBAAZ,CAAY,CACvB;;cAEF,OAAO;gBACNhC,WAAW,EAAE3H,aAAa,CAACyJ,MAAM,CAACzD,WAAW,CAAC;gBAC9C8B,SAAS,EAAE7H,kBAAkB,CAACwJ,MAAM,CAAC1B,SAAS,CAAC;gBAC/C6B,QAAQ,EAAE5J,aAAa,CAACyJ,MAAM,CAACI,QAAQ,CAAC;gBACxCC,UAAU,EAAEN,cAAc;gBAC1BpD,QAAQ,EAAE;kBACTC,UAAU,EAAEoD,MAAM,CAACnD,UAAU;kBAC7B0B,IAAI,EAAEhI,aAAa,CAACyJ,MAAM,CAACxB,IAAI;;eAEhC;YACF,CAAC,CAAC;YACF,sBAAO;cAAEb,QAAQ,EAAEK;YAAK,CAAE;;;YAE1B,sBAAOhH,OAAO,CAAC+B,MAAM,CAACuH,KAAG,CAAC;;;;;;GAG5B;;EAEOxJ,mEAAqB,GAA7B,UAA8BuI,eAAuB;IACpD,OAAO,CAAC,EAAE,GAAGA,eAAe,EAAEkB,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC;EAClD,CAAC;EACF,0CAAC;AAAD,CAAC,CA3awDhL,mCAAmC;;AA6a5F,SAASmE,uCAAuCA;EAC/C,OAAOrE,yBAAyB,CAAC;IAChCmL,QAAQ,EAAEtL,QAAQ,CAACuL,WAAW;IAC9BC,MAAM,EAAEtL,iBAAiB,CAACuL;GAC1B,CAAC;AACH","names":["Category","Credentials","PredictionsAction","getAmplifyUserAgentObject","Storage","AbstractIdentifyPredictionsProvider","RekognitionClient","SearchFacesByImageCommand","DetectTextCommand","DetectLabelsCommand","DetectFacesCommand","DetectModerationLabelsCommand","RecognizeCelebritiesCommand","isStorageSource","isFileSource","isBytesSource","isIdentifyCelebrities","isIdentifyFromCollection","TextractClient","DetectDocumentTextCommand","AnalyzeDocumentCommand","makeCamelCase","makeCamelCaseArray","blobToArrayBuffer","categorizeRekognitionBlocks","categorizeTextractBlocks","__extends","_super","AmazonAIIdentifyPredictionsProvider","source","Promise","res","rej","storageConfig","level","identityId","get","key","then","url","parser","parsedURL","match","length","S3Object","Bucket","Name","decodeURIComponent","catch","err","file","Bytes","Uint8Array","buffer","bytes","Blob","ArrayBuffer","Buffer","input","credentials","_f","reject","_a","_config","_b","_c","region","_d","_e","configFormat","rekognitionClient","customUserAgent","_getPredictionsIdentifyAmplifyUserAgent","textractClient","configureSource","text","inputDocument","err_1","format","featureTypes","push","textractParam","Document","rekognitionParam","Image","detectTextCommand","send","rekognitionData","rekognitionResponse","TextDetections","words","detectDocumentTextCommand","Blocks","err_2","param","FeatureTypes","analyzeDocumentCommand","err_3","type","labels","inputImage_1","data","servicePromises","entityType","detectLabels","detectModerationLabels","all","identifyResult","forEach","val","err_4","detectLabelsCommand","Labels","detectLabelData","map","boxes","Instances","BoundingBox","undefined","name","boundingBoxes","metadata","confidence","Confidence","parents","Parents","err_5","detectModerationLabelsCommand","ModerationLabels","unsafe","err_6","_m","celebrityDetectionEnabled","_g","collectionIdConfig","_h","maxFacesConfig","entities","inputImage","Attributes","celebrityDetection","recognizeCelebritiesCommand","faces","CelebrityFaces","boundingBox","celebrity","Face","landmarks","Landmarks","pose","Pose","err_7","collection","_j","_k","collectionId","_l","maxFaces","updatedParam","CollectionId","MaxFaces","searchFacesByImageCommand","FaceMatches","externalImageId","_this","decodeExternalImageId","ExternalImageId","similarity","Similarity","err_8","detectFacesCommand","FaceDetails","attributeKeys","faceAttributes","detail","Emotions","Type","ageRange","AgeRange","attributes","err_9","replace","category","Predictions","action","Identify"],"sources":["/Workshop/product-metadata/guidance-for-generating-product-descriptions-with-bedrock/source/frontend/node_modules/@aws-amplify/predictions/src/Providers/AmazonAIIdentifyPredictionsProvider.ts"],"sourcesContent":["// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport {\n\tCategory,\n\tCredentials,\n\tConsoleLogger as Logger,\n\tPredictionsAction,\n\tgetAmplifyUserAgentObject,\n} from '@aws-amplify/core';\nimport { Storage } from '@aws-amplify/storage';\nimport { AbstractIdentifyPredictionsProvider } from '../types/Providers';\nimport {\n\tRekognitionClient,\n\tSearchFacesByImageCommand,\n\tDetectTextCommand,\n\tDetectTextCommandInput,\n\tDetectLabelsCommand,\n\tDetectLabelsCommandInput,\n\tDetectFacesCommand,\n\tDetectModerationLabelsCommand,\n\tDetectModerationLabelsCommandInput,\n\tRecognizeCelebritiesCommand,\n} from '@aws-sdk/client-rekognition';\nimport {\n\tIdentifyLabelsInput,\n\tIdentifyLabelsOutput,\n\tIdentifySource,\n\tIdentifyEntitiesInput,\n\tIdentifyEntitiesOutput,\n\tisStorageSource,\n\tisFileSource,\n\tisBytesSource,\n\tIdentifyTextInput,\n\tIdentifyTextOutput,\n\tisIdentifyCelebrities,\n\tisIdentifyFromCollection,\n\tIdentifyFromCollection,\n\tFeatureTypes,\n} from '../types';\nimport {\n\tImage,\n\tDocument,\n\tTextDetectionList,\n\tBlockList,\n} from '../types/AWSTypes';\nimport {\n\tTextractClient,\n\tDetectDocumentTextCommand,\n\tDetectDocumentTextCommandInput,\n\tAnalyzeDocumentCommand,\n\tAnalyzeDocumentCommandInput,\n} from '@aws-sdk/client-textract';\nimport { makeCamelCase, makeCamelCaseArray, blobToArrayBuffer } from './Utils';\nimport {\n\tcategorizeRekognitionBlocks,\n\tcategorizeTextractBlocks,\n} from './IdentifyTextUtils';\n\nexport class AmazonAIIdentifyPredictionsProvider extends AbstractIdentifyPredictionsProvider {\n\tprivate rekognitionClient: RekognitionClient;\n\tprivate textractClient: TextractClient;\n\n\tconstructor() {\n\t\tsuper();\n\t}\n\n\tgetProviderName() {\n\t\treturn 'AmazonAIIdentifyPredictionsProvider';\n\t}\n\n\t/**\n\t * Verify user input source and converts it into source object readable by Rekognition and Textract.\n\t * Note that Rekognition and Textract use the same source interface, so we need not worry about types.\n\t * @param {IdentifySource} source - User input source that directs to the object user wants\n\t * to identify (storage, file, or bytes).\n\t * @return {Promise<Image>} - Promise resolving to the converted source object.\n\t */\n\tprivate configureSource(source: IdentifySource): Promise<Image> {\n\t\treturn new Promise((res, rej) => {\n\t\t\tif (isStorageSource(source)) {\n\t\t\t\tconst storageConfig = {\n\t\t\t\t\tlevel: source.level,\n\t\t\t\t\tidentityId: source.identityId,\n\t\t\t\t};\n\t\t\t\tStorage.get(source.key, storageConfig)\n\t\t\t\t\t.then((url: string) => {\n\t\t\t\t\t\tconst parser =\n\t\t\t\t\t\t\t/https:\\/\\/([a-zA-Z0-9%\\-_.]+)\\.s3\\.[A-Za-z0-9%\\-._~]+\\/([a-zA-Z0-9%\\-._~/]+)\\?/;\n\t\t\t\t\t\tconst parsedURL = url.match(parser);\n\t\t\t\t\t\tif (parsedURL.length < 3) rej('Invalid S3 key was given.');\n\t\t\t\t\t\tres({\n\t\t\t\t\t\t\tS3Object: {\n\t\t\t\t\t\t\t\tBucket: parsedURL[1],\n\t\t\t\t\t\t\t\tName: decodeURIComponent(parsedURL[2]),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t});\n\t\t\t\t\t})\n\t\t\t\t\t.catch(err => rej(err));\n\t\t\t} else if (isFileSource(source)) {\n\t\t\t\tblobToArrayBuffer(source.file)\n\t\t\t\t\t.then(buffer => {\n\t\t\t\t\t\tres({ Bytes: new Uint8Array(buffer) });\n\t\t\t\t\t})\n\t\t\t\t\t.catch(err => rej(err));\n\t\t\t} else if (isBytesSource(source)) {\n\t\t\t\tconst bytes = source.bytes;\n\t\t\t\tif (bytes instanceof Blob) {\n\t\t\t\t\tblobToArrayBuffer(bytes)\n\t\t\t\t\t\t.then(buffer => {\n\t\t\t\t\t\t\tres({ Bytes: new Uint8Array(buffer) });\n\t\t\t\t\t\t})\n\t\t\t\t\t\t.catch(err => rej(err));\n\t\t\t\t}\n\t\t\t\tif (bytes instanceof ArrayBuffer || bytes instanceof Buffer) {\n\t\t\t\t\tres({ Bytes: new Uint8Array(bytes) } as Image);\n\t\t\t\t}\n\t\t\t\t// everything else can be directly passed to Rekognition / Textract.\n\t\t\t\tres({ Bytes: bytes } as Image);\n\t\t\t} else {\n\t\t\t\trej('Input source is not configured correctly.');\n\t\t\t}\n\t\t});\n\t}\n\n\t/**\n\t * Recognize text from real-world images and documents (plain text, forms and tables). Detects text in the input\n\t * image and converts it into machine-readable text.\n\t * @param {IdentifySource} source - Object containing the source image and feature types to analyze.\n\t * @return {Promise<IdentifyTextOutput>} - Promise resolving to object containing identified texts.\n\t */\n\tprotected async identifyText(\n\t\tinput: IdentifyTextInput\n\t): Promise<IdentifyTextOutput> {\n\t\tconst credentials = await Credentials.get();\n\t\tif (!credentials) return Promise.reject('No credentials');\n\t\tconst {\n\t\t\tidentifyText: {\n\t\t\t\tregion = '',\n\t\t\t\tdefaults: { format: configFormat = 'PLAIN' } = {},\n\t\t\t} = {},\n\t\t} = this._config;\n\t\tthis.rekognitionClient = new RekognitionClient({\n\t\t\tregion,\n\t\t\tcredentials,\n\t\t\tcustomUserAgent: _getPredictionsIdentifyAmplifyUserAgent(),\n\t\t});\n\t\tthis.textractClient = new TextractClient({\n\t\t\tregion,\n\t\t\tcredentials,\n\t\t\tcustomUserAgent: _getPredictionsIdentifyAmplifyUserAgent(),\n\t\t});\n\t\tlet inputDocument: Document;\n\n\t\ttry {\n\t\t\tinputDocument = await this.configureSource(input.text.source);\n\t\t} catch (err) {\n\t\t\treturn Promise.reject(err);\n\t\t}\n\n\t\t// get default value if format isn't specified in the input.\n\t\tconst format = input.text.format || configFormat;\n\t\tconst featureTypes: FeatureTypes = []; // structures we want to analyze (e.g. [TABLES, FORMS]).\n\t\tif (format === 'FORM' || format === 'ALL') featureTypes.push('FORMS');\n\t\tif (format === 'TABLE' || format === 'ALL') featureTypes.push('TABLES');\n\n\t\tif (featureTypes.length === 0) {\n\t\t\t/**\n\t\t\t * Empty featureTypes indicates that we will identify plain text. We will use rekognition (suitable\n\t\t\t * for everyday images but has 50 word limit) first and see if reaches its word limit. If it does, then\n\t\t\t * we call textract and use the data that identify more words.\n\t\t\t */\n\t\t\tconst textractParam: DetectDocumentTextCommandInput = {\n\t\t\t\tDocument: inputDocument,\n\t\t\t};\n\t\t\tconst rekognitionParam: DetectTextCommandInput = {\n\t\t\t\tImage: inputDocument,\n\t\t\t};\n\n\t\t\ttry {\n\t\t\t\tconst detectTextCommand = new DetectTextCommand(rekognitionParam);\n\t\t\t\tconst rekognitionData = await this.rekognitionClient.send(\n\t\t\t\t\tdetectTextCommand\n\t\t\t\t);\n\n\t\t\t\tconst rekognitionResponse = categorizeRekognitionBlocks(\n\t\t\t\t\trekognitionData.TextDetections as TextDetectionList\n\t\t\t\t);\n\t\t\t\tif (rekognitionResponse.text.words.length < 50) {\n\t\t\t\t\t// did not hit the word limit, return the data\n\t\t\t\t\treturn rekognitionResponse;\n\t\t\t\t}\n\n\t\t\t\tconst detectDocumentTextCommand = new DetectDocumentTextCommand(\n\t\t\t\t\ttextractParam\n\t\t\t\t);\n\n\t\t\t\tconst { Blocks } = await this.textractClient.send(\n\t\t\t\t\tdetectDocumentTextCommand\n\t\t\t\t);\n\n\t\t\t\tif (rekognitionData.TextDetections.length > Blocks.length) {\n\t\t\t\t\treturn rekognitionResponse;\n\t\t\t\t}\n\n\t\t\t\treturn categorizeTextractBlocks(Blocks as BlockList);\n\t\t\t} catch (err) {\n\t\t\t\tPromise.reject(err);\n\t\t\t}\n\t\t} else {\n\t\t\tconst param: AnalyzeDocumentCommandInput = {\n\t\t\t\tDocument: inputDocument,\n\t\t\t\tFeatureTypes: featureTypes,\n\t\t\t};\n\n\t\t\ttry {\n\t\t\t\tconst analyzeDocumentCommand = new AnalyzeDocumentCommand(param);\n\t\t\t\tconst { Blocks } = await this.textractClient.send(\n\t\t\t\t\tanalyzeDocumentCommand\n\t\t\t\t);\n\t\t\t\treturn categorizeTextractBlocks(Blocks as BlockList);\n\t\t\t} catch (err) {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Identify instances of real world entities from an image and if it contains unsafe content.\n\t * @param {IdentifyLabelsInput} input - Object containing the source image and entity type to identify.\n\t * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to an array of identified entities.\n\t */\n\tprotected async identifyLabels(\n\t\tinput: IdentifyLabelsInput\n\t): Promise<IdentifyLabelsOutput> {\n\t\ttry {\n\t\t\tconst credentials = await Credentials.get();\n\t\t\tif (!credentials) return Promise.reject('No credentials');\n\t\t\tconst {\n\t\t\t\tidentifyLabels: {\n\t\t\t\t\tregion = '',\n\t\t\t\t\tdefaults: { type = 'LABELS' } = {},\n\t\t\t\t} = {},\n\t\t\t} = this._config;\n\t\t\tthis.rekognitionClient = new RekognitionClient({\n\t\t\t\tregion,\n\t\t\t\tcredentials,\n\t\t\t\tcustomUserAgent: _getPredictionsIdentifyAmplifyUserAgent(),\n\t\t\t});\n\t\t\tlet inputImage: Image;\n\t\t\tawait this.configureSource(input.labels.source)\n\t\t\t\t.then(data => {\n\t\t\t\t\tinputImage = data;\n\t\t\t\t})\n\t\t\t\t.catch(err => {\n\t\t\t\t\treturn Promise.reject(err);\n\t\t\t\t});\n\t\t\tconst param = { Image: inputImage };\n\t\t\tconst servicePromises = [];\n\n\t\t\t// get default argument\n\t\t\tconst entityType = input.labels.type || type;\n\t\t\tif (entityType === 'LABELS' || entityType === 'ALL') {\n\t\t\t\tservicePromises.push(this.detectLabels(param));\n\t\t\t}\n\t\t\tif (entityType === 'UNSAFE' || entityType === 'ALL') {\n\t\t\t\tservicePromises.push(this.detectModerationLabels(param));\n\t\t\t}\n\n\t\t\treturn Promise.all(servicePromises)\n\t\t\t\t.then(data => {\n\t\t\t\t\tlet identifyResult: IdentifyLabelsOutput = {};\n\t\t\t\t\t// concatenate resolved promises to a single object\n\t\t\t\t\tdata.forEach(val => {\n\t\t\t\t\t\tidentifyResult = { ...identifyResult, ...val };\n\t\t\t\t\t});\n\t\t\t\t\treturn identifyResult;\n\t\t\t\t})\n\t\t\t\t.catch(err => Promise.reject(err));\n\t\t} catch (err) {\n\t\t\treturn Promise.reject(err);\n\t\t}\n\t}\n\n\t/**\n\t * Calls Rekognition.detectLabels and organizes the returned data.\n\t * @param {DetectLabelsInput} param - parameter to be passed onto Rekognition\n\t * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectLabels response.\n\t */\n\tprivate async detectLabels(\n\t\tparam: DetectLabelsCommandInput\n\t): Promise<IdentifyLabelsOutput> {\n\t\ttry {\n\t\t\tconst detectLabelsCommand = new DetectLabelsCommand(param);\n\t\t\tconst data = await this.rekognitionClient.send(detectLabelsCommand);\n\t\t\tif (!data.Labels) return { labels: null }; // no image was detected\n\t\t\tconst detectLabelData = data.Labels.map(val => {\n\t\t\t\tconst boxes = val.Instances\n\t\t\t\t\t? val.Instances.map(val => makeCamelCase(val.BoundingBox))\n\t\t\t\t\t: undefined;\n\t\t\t\treturn {\n\t\t\t\t\tname: val.Name,\n\t\t\t\t\tboundingBoxes: boxes,\n\t\t\t\t\tmetadata: {\n\t\t\t\t\t\tconfidence: val.Confidence,\n\t\t\t\t\t\tparents: makeCamelCaseArray(val.Parents),\n\t\t\t\t\t},\n\t\t\t\t};\n\t\t\t});\n\t\t\treturn { labels: detectLabelData };\n\t\t} catch (err) {\n\t\t\treturn Promise.reject(err);\n\t\t}\n\t}\n\n\t/**\n\t * Calls Rekognition.detectModerationLabels and organizes the returned data.\n\t * @param {Rekognition.DetectLabelsRequest} param - Parameter to be passed onto Rekognition\n\t * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectModerationLabels response.\n\t */\n\tprivate async detectModerationLabels(\n\t\tparam: DetectModerationLabelsCommandInput\n\t): Promise<IdentifyLabelsOutput> {\n\t\ttry {\n\t\t\tconst detectModerationLabelsCommand = new DetectModerationLabelsCommand(\n\t\t\t\tparam\n\t\t\t);\n\t\t\tconst data = await this.rekognitionClient.send(\n\t\t\t\tdetectModerationLabelsCommand\n\t\t\t);\n\t\t\tif (data.ModerationLabels.length !== 0) {\n\t\t\t\treturn { unsafe: 'YES' };\n\t\t\t} else {\n\t\t\t\treturn { unsafe: 'NO' };\n\t\t\t}\n\t\t} catch (err) {\n\t\t\treturn Promise.reject(err);\n\t\t}\n\t}\n\n\t/**\n\t * Identify faces within an image that is provided as input, and match faces from a collection\n\t * or identify celebrities.\n\t * @param {IdentifyEntityInput} input - object containing the source image and face match options.\n\t * @return {Promise<IdentifyEntityOutput>} Promise resolving to identify results.\n\t */\n\tprotected async identifyEntities(\n\t\tinput: IdentifyEntitiesInput\n\t): Promise<IdentifyEntitiesOutput> {\n\t\tconst credentials = await Credentials.get();\n\t\tif (!credentials) return Promise.reject('No credentials');\n\t\tconst {\n\t\t\tidentifyEntities: {\n\t\t\t\tregion = '',\n\t\t\t\tcelebrityDetectionEnabled = false,\n\t\t\t\tdefaults: {\n\t\t\t\t\tcollectionId: collectionIdConfig = '',\n\t\t\t\t\tmaxEntities: maxFacesConfig = 50,\n\t\t\t\t} = {},\n\t\t\t} = {},\n\t\t} = this._config;\n\t\t// default arguments\n\n\t\tthis.rekognitionClient = new RekognitionClient({\n\t\t\tregion,\n\t\t\tcredentials,\n\t\t\tcustomUserAgent: _getPredictionsIdentifyAmplifyUserAgent(),\n\t\t});\n\t\tlet inputImage: Image;\n\t\tawait this.configureSource(input.entities.source)\n\t\t\t.then(data => (inputImage = data))\n\t\t\t.catch(err => {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t});\n\n\t\tconst param = { Attributes: ['ALL'], Image: inputImage };\n\n\t\tif (\n\t\t\tisIdentifyCelebrities(input.entities) &&\n\t\t\tinput.entities.celebrityDetection\n\t\t) {\n\t\t\tif (!celebrityDetectionEnabled) {\n\t\t\t\treturn Promise.reject(\n\t\t\t\t\t'Error: You have to enable celebrity detection first'\n\t\t\t\t);\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tconst recognizeCelebritiesCommand = new RecognizeCelebritiesCommand(\n\t\t\t\t\tparam\n\t\t\t\t);\n\t\t\t\tconst data = await this.rekognitionClient.send(\n\t\t\t\t\trecognizeCelebritiesCommand\n\t\t\t\t);\n\t\t\t\tconst faces = data.CelebrityFaces.map(celebrity => {\n\t\t\t\t\treturn {\n\t\t\t\t\t\tboundingBox: makeCamelCase(celebrity.Face.BoundingBox),\n\t\t\t\t\t\tlandmarks: makeCamelCaseArray(celebrity.Face.Landmarks),\n\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\t...makeCamelCase(celebrity, ['Id', 'Name', 'Urls']),\n\t\t\t\t\t\t\tpose: makeCamelCase(celebrity.Face.Pose),\n\t\t\t\t\t\t},\n\t\t\t\t\t};\n\t\t\t\t});\n\t\t\t\treturn { entities: faces };\n\t\t\t} catch (err) {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t}\n\t\t} else if (\n\t\t\tisIdentifyFromCollection(input.entities) &&\n\t\t\tinput.entities.collection\n\t\t) {\n\t\t\tconst {\n\t\t\t\tcollectionId = collectionIdConfig,\n\t\t\t\tmaxEntities: maxFaces = maxFacesConfig,\n\t\t\t} = input.entities as IdentifyFromCollection;\n\t\t\t// Concatenate additional parameters\n\t\t\tconst updatedParam = {\n\t\t\t\t...param,\n\t\t\t\tCollectionId: collectionId,\n\t\t\t\tMaxFaces: maxFaces,\n\t\t\t};\n\t\t\ttry {\n\t\t\t\tconst searchFacesByImageCommand = new SearchFacesByImageCommand(\n\t\t\t\t\tupdatedParam\n\t\t\t\t);\n\t\t\t\tconst data = await this.rekognitionClient.send(\n\t\t\t\t\tsearchFacesByImageCommand\n\t\t\t\t);\n\t\t\t\tconst faces = data.FaceMatches.map(val => {\n\t\t\t\t\treturn {\n\t\t\t\t\t\tboundingBox: makeCamelCase(val.Face.BoundingBox),\n\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\texternalImageId: this.decodeExternalImageId(\n\t\t\t\t\t\t\t\tval.Face.ExternalImageId\n\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\tsimilarity: val.Similarity,\n\t\t\t\t\t\t},\n\t\t\t\t\t};\n\t\t\t\t});\n\t\t\t\treturn { entities: faces };\n\t\t\t} catch (err) {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t}\n\t\t} else {\n\t\t\ttry {\n\t\t\t\tconst detectFacesCommand = new DetectFacesCommand(param);\n\t\t\t\tconst data = await this.rekognitionClient.send(detectFacesCommand);\n\t\t\t\tconst faces = data.FaceDetails.map(detail => {\n\t\t\t\t\t// face attributes keys we want to extract from Rekognition's response\n\t\t\t\t\tconst attributeKeys = [\n\t\t\t\t\t\t'Smile',\n\t\t\t\t\t\t'Eyeglasses',\n\t\t\t\t\t\t'Sunglasses',\n\t\t\t\t\t\t'Gender',\n\t\t\t\t\t\t'Beard',\n\t\t\t\t\t\t'Mustache',\n\t\t\t\t\t\t'EyesOpen',\n\t\t\t\t\t\t'MouthOpen',\n\t\t\t\t\t];\n\t\t\t\t\tconst faceAttributes = makeCamelCase(detail, attributeKeys);\n\t\t\t\t\tif (detail.Emotions) {\n\t\t\t\t\t\tfaceAttributes['emotions'] = detail.Emotions.map(\n\t\t\t\t\t\t\temotion => emotion.Type\n\t\t\t\t\t\t);\n\t\t\t\t\t}\n\t\t\t\t\treturn {\n\t\t\t\t\t\tboundingBox: makeCamelCase(detail.BoundingBox),\n\t\t\t\t\t\tlandmarks: makeCamelCaseArray(detail.Landmarks),\n\t\t\t\t\t\tageRange: makeCamelCase(detail.AgeRange),\n\t\t\t\t\t\tattributes: faceAttributes,\n\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\tconfidence: detail.Confidence,\n\t\t\t\t\t\t\tpose: makeCamelCase(detail.Pose),\n\t\t\t\t\t\t},\n\t\t\t\t\t};\n\t\t\t\t});\n\t\t\t\treturn { entities: faces };\n\t\t\t} catch (err) {\n\t\t\t\treturn Promise.reject(err);\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate decodeExternalImageId(externalImageId: string): string {\n\t\treturn ('' + externalImageId).replace(/::/g, '/');\n\t}\n}\n\nfunction _getPredictionsIdentifyAmplifyUserAgent() {\n\treturn getAmplifyUserAgentObject({\n\t\tcategory: Category.Predictions,\n\t\taction: PredictionsAction.Identify,\n\t});\n}\n"]},"metadata":{},"sourceType":"module","externalDependencies":[]}